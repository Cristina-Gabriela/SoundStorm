model:
  target: sound_synthesis2.modeling.dalle_wav.DALLE
  params:
    content_info: {key: audio}
    condition_info: {key: text}
    n_q: 3  # the encodec codebook's number
    diffusion_config:      
        target: sound_synthesis2.modeling.transformers.diffusion_transformer_wav_v2_share.DiffusionTransformer
        params:
          diffusion_step: 100
          n_q: 3
          alpha_init_type: 'alpha1'       # init_type = fix or cos or linear 
          auxiliary_loss_weight: 5.0e-4
          adaptive_auxiliary_loss: True
          mask_weight: [1, 1]    # the loss weight on mask region and non-mask region

          transformer_config:
            target: sound_synthesis2.modeling.transformers.transformer_utils_wav_unet_share_3code.Text2ImageTransformer
            params:
              attn_type: 'selfcross' # using self attention
              n_q: 3
              n_layer: 16 # we may use large model
              n_embd: 512 # the dim of embedding dims
              condition_dim: 512
              n_head: 8 
              attn_pdrop: 0.0
              resid_pdrop: 0.0
              block_activate: GELU2
              timestep_type: 'adalayernorm'    # adainsnorm or adalayernorm and abs
              mlp_hidden_times: 4
              
              content_emb_config:
                target: sound_synthesis2.modeling.embeddings.dalle_mask_wav_embedding1d_3code.DalleMaskImageEmbedding
                params:
                  num_embed: 1026    #should be quantize_number
                  max_size: 16000
                  n_q: 3
                  embed_dim: 512 # the dim of postion embedding
                  trainable: True
                  pos_emb_type: embedding  